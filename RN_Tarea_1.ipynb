{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RN_Tarea_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK_v-b3-GPr1"
      },
      "source": [
        "# Tarea pytorch, parte A\n",
        "\n",
        "Recuerda que no se vale utilizar la palabra `for`.\n",
        "\n",
        "1. Encuentra la derivada de $x^2 + 2x + 5$ evaluada en $x = 1$ (con pytorch).\n",
        "2. ¿Para qué sirve squeeze y unsqueeze? ¿Qué recomiendo usar en vez de unsqueeze? \n",
        "3. Si tengo una matriz `A` de $8\\times 10$, ¿de qué tamaño será `A[1:6,-2:]`?\n",
        "4. Súmale 10 al primer renglón y 20 al segundo renglón. Escribe poquito.\n",
        "5. Crea una matriz de $n\\times m$ donde en la entrada $(i,j)$ esté el número $i+j$. No se vale usar la palabra `for`. Con `arange` e indizar.\n",
        "6. Dado dos tensores lineales de tamaño $n\\times 2$ y $m \\times 2$ respectivamente, crea una matriz de $n\\times m$ en donde la entrada $(i,j)$ sea la distancia euclideana entre el punto $i$ del primero tensor y el punto $j$ del segundo tensor. Igual, la palabra `for` está prohibida.\n",
        "7. Dado una matriz $A$ de $n\\times m$ y un vector de enteros $b$ donde todos los números de $b$ van del 0 a m, selecciona los números en las columnas correspondientes a $b$ y ponlos como $-1$. Por ejemplo, si \n",
        "\n",
        "$$A = \\begin{bmatrix}\n",
        "        0 & 1 & 2 & 3 \\\\\n",
        "        4 & 5 & 6 & 7 \\\\\n",
        "      \\end{bmatrix}$$\n",
        "y $b = [2, 0]$, entonces debe resultar en:\n",
        "\n",
        "$$A = \\begin{bmatrix}\n",
        "        0 & 1 & -1 & 3 \\\\\n",
        "        -1 & 5 & 6 & 7 \\\\\n",
        "      \\end{bmatrix}$$\n",
        "      \n",
        "8. (**difícil**) Implementa, sin usar `@` ni matmul, multiplicación de matrices. Se vale usar `*`, `+`, `sum` y broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XLvXkwdBOZC"
      },
      "source": [
        "import torch\n",
        "import fastai"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnLb6w2nBXqq",
        "outputId": "c7a80bcf-c2dc-4716-ce0c-25540415656c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KWYbPFyRVo5"
      },
      "source": [
        "# 1. Encuentra la derivada de x2+2x+5 evaluada en x=1 (con pytorch).\n",
        "> **R: 4**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukqitJopoBgD",
        "outputId": "11072015-bbde-4aba-aa17-6ed562efa7ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def derivate(x,y):\n",
        "  \"\"\"\n",
        "  x = Tensor to evaluate (the point on X)\n",
        "  y = your function \n",
        "  \"\"\"\n",
        "  y.backward() #backward guarda nuestros gradientes en hojas\n",
        "  result = x.grad #grad recupera los gradientes en hojas, los suma usando la regla de la cadena  y arroja el resultado\n",
        "  return(result)\n",
        "\n",
        "#x = torch([[1.]],requires_grad=True)\n",
        "#Autograd nos proporciona funciones para hacer las diferenciales de manera automatica\n",
        "#Para hacer uso de ello introducimos True para el parámetro requires_grad\n",
        "#NOTA: debe de ser un tensor escalar (Ya que la salida tras evaluar es un único número)de punto flotante \n",
        "#ya que no hay soporte para otros\n",
        "x = torch.tensor([1.], requires_grad=True) \n",
        "y = x**2 + 2*x + 5 # Escribimos nuestra función\n",
        "\n",
        "#y.backward() #backward guarda nuestros gradientes en hojas\n",
        "#x.grad #grad recupera los gradientes en hojas, los suma usando la regla de la cadena  y arroja el resultadod\n",
        "derivate(x, y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV1_shDv9OBC"
      },
      "source": [
        "# 2. ¿Para qué sirve squeeze y unsqueeze? \n",
        "###squeeze: Quita todas las dimensiones de valor 1\n",
        "> Si tenemos: torch.tensor([1, 3, 1, 1, 4, 5]) y aplicamos squeeze\n",
        "> Ahora tendremos torch.tensor([3, 4, 5])\n",
        "###unsqueeze: Hace lo contrario a squeeze, te añade dimensión 1 \n",
        "> si tenemos: torch.tensor([3,4,5]) y aplicamos unsqueeze(1) \n",
        "> Ahora tendremos torch.tensor([3,1,4,5]), añade la dimensión en \n",
        "el lugar que le pasas como parámetro, comenzando desde cero\n",
        "# 2.1. ¿Qué recomiendo usar en vez de unsqueeze?\n",
        "> Usar la palabra reservada **None**, ya que combinado con las listas,\n",
        "puede hacer lo mismo que unsqueeze pero es un poco más rápido.\n",
        "Sí tenemos torch.tensor([1,3,1,1,4,5]) su dimensión es [6] = x.shape\n",
        "pero si queremos añadir una más, basta con hacer x[:,None] = [6,1] = x.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N7fKPrXUcZE",
        "outputId": "54908e62-3f76-4e74-b101-b01e4d2278f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.zeros(2, 1, 2, 1, 2, 3, 5, 1)\n",
        "#y = torch.squeeze(x, 0) # Si pasamos el indice cero, el tensor se queda igual\n",
        "#y = torch.squeeze(x, 1) # Si paso como indice el uno, sólo se elimina un uno del tensor, no entiendo muy bien la razón. \n",
        "# Crei que si copiaba la misma línea una segunda vez, se eliminaria el segundo uno pero no fue así.\n",
        "x.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 2, 1, 2, 3, 5, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iQacdaQCDQF",
        "outputId": "98fb955e-6d82-4d36-c19b-74e763bd13bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = torch.squeeze(x) # Si no paso nada, se comprime tal como lo dice la documentación, se comprimen todos los valores 1's \n",
        "y.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 2, 3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGVVl5thBstr",
        "outputId": "879bf11a-e707-47b4-e1ed-52d527446f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([1, 2, 3, 4,5,6,7,8,9,11,1])\n",
        "#torch.unsqueeze(x, 0) # Si pasamos como indice el valor cero, deja el tensor como esta\n",
        "x.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGygP2qPCO7L",
        "outputId": "d25e3ef9-a2aa-4c8b-b04d-dbfa454500b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = torch.unsqueeze(x, 1); y.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbTX_E_6CgDc",
        "outputId": "6b6819c3-6312-4802-83fc-d900010a9d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y[:,:,None].shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7vxMw5AFhRj",
        "outputId": "f0c82543-2412-4192-ce04-430f6a07e303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([1, 3, 1, 1, 4, 5]); x.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkjDWwWqFqqc",
        "outputId": "8db49422-a79a-4f5c-ddf3-237ebe5f9233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x[:].shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwY5PBYISjdm",
        "outputId": "e728a18c-a22f-41d7-a780-0f606813d097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x[:,None].shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_yelAQiTgZm"
      },
      "source": [
        "# 3. Si tengo una matriz `A` de $8\\times 10$, ¿de qué tamaño será `A[1:6,-2:]`?\n",
        "**R: 5 filas y 2 columnas, dado que toma la fila uno hasta la 5,\n",
        "ya que no incluye al 6, y columnas -2: significa que tomara las dos primeras comenzando desde el final hasta el inicio.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0i-CpzKTm7G",
        "outputId": "f39c1f71-e4a1-4da2-fefd-63a238e1849b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "A = torch.rand(8,10);\n",
        "A.shape\n",
        "# Alto, Ancho, Profundo\n",
        "# Números aleatorios entre cero y uno [0, 1]\n",
        "# Distribuidos uniformemente"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7oTjesiT3pG",
        "outputId": "6a918926-7e78-4c05-a2fc-96dd557cf7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " A[1:6,-2:].shape # Toma la fila uno hasta la 5, no incluye 6, y toma las dos últimas columnas"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQzAvAm4W6AI",
        "outputId": "452e640f-033d-4f72-a3b9-226b878fc730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "A"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9768, 0.6018, 0.9144, 0.0079, 0.6518, 0.5264, 0.9401, 0.2835, 0.6769,\n",
              "         0.9508],\n",
              "        [0.9443, 0.6794, 0.5771, 0.8815, 0.8549, 0.6018, 0.5081, 0.0702, 0.8621,\n",
              "         0.1491],\n",
              "        [0.4326, 0.3925, 0.4982, 0.0288, 0.1652, 0.6724, 0.4187, 0.6820, 0.9770,\n",
              "         0.2109],\n",
              "        [0.1780, 0.1360, 0.9867, 0.9970, 0.2858, 0.7942, 0.8048, 0.3913, 0.8990,\n",
              "         0.2160],\n",
              "        [0.6545, 0.1152, 0.2985, 0.1026, 0.5033, 0.4175, 0.8402, 0.9477, 0.3787,\n",
              "         0.5549],\n",
              "        [0.3857, 0.8621, 0.5115, 0.9454, 0.4239, 0.1973, 0.1146, 0.5811, 0.2549,\n",
              "         0.6971],\n",
              "        [0.4262, 0.0844, 0.9593, 0.1174, 0.8946, 0.4388, 0.0216, 0.2426, 0.8292,\n",
              "         0.5528],\n",
              "        [0.1541, 0.4336, 0.2459, 0.5148, 0.9363, 0.5342, 0.6586, 0.2000, 0.7652,\n",
              "         0.6066]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6st-SIcW7Xh",
        "outputId": "c84a89a8-61ea-4460-dc37-8031c42a3504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "A = A[1:6,-2:]; A"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8621, 0.1491],\n",
              "        [0.9770, 0.2109],\n",
              "        [0.8990, 0.2160],\n",
              "        [0.3787, 0.5549],\n",
              "        [0.2549, 0.6971]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5y0frf-a6dV"
      },
      "source": [
        "# 4. Súmale 10 al primer renglón y 20 al segundo renglón. Escribe poquito."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yAIXys2YJ5v",
        "outputId": "8fafd42a-3a79-4769-f04d-10828fdc0b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "A"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8621, 0.1491],\n",
              "        [0.9770, 0.2109],\n",
              "        [0.8990, 0.2160],\n",
              "        [0.3787, 0.5549],\n",
              "        [0.2549, 0.6971]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAHi2XhYbr7T",
        "outputId": "ebe59c72-e3c4-4322-8444-3378345b3573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "A[0] +=10; A[1] += 20; A # No sabíía si el 4 se referia a la matriz obtenida en 3 por lo que supuse que\n",
        "# debia de continuar con esa matriz y es por ello que es esa matriz a la que le sume 10 a la primer\n",
        "# fila y 20 a la segunda fila"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10.8621, 10.1491],\n",
              "        [20.9770, 20.2109],\n",
              "        [ 0.8990,  0.2160],\n",
              "        [ 0.3787,  0.5549],\n",
              "        [ 0.2549,  0.6971]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTXzyxzPcaKO"
      },
      "source": [
        "# 5. Crea una matriz de $n\\times m$ donde en la entrada $(i,j)$ esté el número $i+j$. No se vale usar la palabra `for`. Con `arange` e indizar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULkNp-ErcZz8"
      },
      "source": [
        "**Este texto es una explicación del autor para si mismo, por lo que la persona que este revisando esto se lo puede saltar.**\n",
        "> Únicamente me queria explicar el funcionamiento o lo que pasaba tras bambalinas con broadcasting. \n",
        "A partir de lo anterior puedo describirme y explicarme a mi mismo los \n",
        "pasos del broadcasting para llegar al resultado: \n",
        "\n",
        "A = [0.0253, 0.3179, 0.4786]\n",
        "B = [0,1,2]\n",
        "B[:,None] = [[0], [1], [2]]\n",
        "\n",
        "A+B[:,None]=[[0.0253, 0.3179, 0.4786], [1.0253, 1.3179, 1.4786], [2.0253, 2.3179, 2.4786]]\n",
        "\n",
        "Para llegar a ese resultado mediante broadcasting (siguiendo la explicacióón de Raggi en el vídeo) fue: \n",
        "\n",
        "**Alineación**\n",
        "\n",
        "|3|1|\n",
        "|-|-|\n",
        "| |3|\n",
        " \n",
        "Donde 3,1 es la dimensión de la matriz B[:, None] y 3 la dimensión de la matriz A.\n",
        "\n",
        "**Igualación superior**\n",
        "\n",
        "|3|3|\n",
        "|-|-|\n",
        "|1|3|\n",
        "\n",
        "Dónde ahora la dimensión de la matriz B[:, None] es 3,3 que es igual a: \n",
        "[[0, 0, 0], [1, 1, 1], [2, 2, 2]] = B[:, None]\n",
        "y la dimensión de la matriz A ahora es 1,3 que es igual a: \n",
        "[[0.0253, 0.3179, 0.4786]] = A\n",
        "\n",
        "**Igualación inferior**\n",
        "\n",
        "Donde la dimensióón de la matriz B[:, None] es 3,3 tal como se describio en el paso anterior pero ahora la dimensióón de la matriz A es 3,3 que es igual a: \n",
        "[[0.0253, 0.3179, 0.4786], [0.0253, 0.3179, 0.4786], [0.0253, 0.3179, 0.4786]] = A\n",
        "\n",
        "Dado que la sumatoria de matriz es coordenada a coordenada, o sea:\n",
        "[[1, 2], [3, 4]] + [[1, 2], [3, 4]] \n",
        "Uno se suma con uno, dos con dos, tres con tres y cuatro con cuatro. \n",
        "\n",
        "Y de esta manera es como se llega al resultado de A+B[:, None]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5WTVBGDb6rb",
        "outputId": "5d1ae6ae-dc29-441d-d5e7-02e6fc9ae25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "def generate_matrix(n,m):\n",
        "  \"\"\"\n",
        "  n=filas\n",
        "  m=columnas\n",
        "  \"\"\"\n",
        "  A = torch.arange(m); B = torch.arange(n)\n",
        "  #print(A, B, \"\\n\")\n",
        "  matrix = A+B[:, None]\n",
        "  return (matrix)\n",
        "\n",
        "print(generate_matrix(5,4))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [1, 2, 3, 4],\n",
            "        [2, 3, 4, 5],\n",
            "        [3, 4, 5, 6],\n",
            "        [4, 5, 6, 7]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAZPO3pNisiG",
        "outputId": "1debbfb4-2873-4fdf-ccbe-3ab399420360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "A = torch.arange(3)\n",
        "B = torch.arange(3)\n",
        "A+B[:,None], A, B"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0, 1, 2],\n",
              "         [1, 2, 3],\n",
              "         [2, 3, 4]]), tensor([0, 1, 2]), tensor([0, 1, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npR4mfu1isVX",
        "outputId": "28990372-bf65-485d-f70b-0a5fb3f6ce2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "AA = A+B[:,None]; AA[2,1]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfvseQln8PcS",
        "outputId": "965911aa-4511-45ca-d88c-9a5f061659b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "A = torch.rand(3)\n",
        "B = torch.arange(3)\n",
        "A.shape, B.shape, B[:,None].shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpeiGbkN8TTj",
        "outputId": "823c7de2-cf7a-45e3-d2a5-373246bcf36a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "A+B[:, None], B, A"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.9768, 0.3205, 0.5127],\n",
              "         [1.9768, 1.3205, 1.5127],\n",
              "         [2.9768, 2.3205, 2.5127]]),\n",
              " tensor([0, 1, 2]),\n",
              " tensor([0.9768, 0.3205, 0.5127]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTDOo_b_8XUV",
        "outputId": "c4b242d1-a394-48e3-e727-bc1c29dbff71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "A, B, B[:,None]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.9768, 0.3205, 0.5127]), tensor([0, 1, 2]), tensor([[0],\n",
              "         [1],\n",
              "         [2]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_qWeI2K_Tw_",
        "outputId": "209a2d35-86ac-4c8c-c59e-6c74476a4bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "A = torch.rand(1,3);A"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1544, 0.0937, 0.8034]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aUnWByF_YMx",
        "outputId": "3cdec742-f80e-43c2-9215-c6e53acc1b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "A = torch.rand(3,3);A"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3664, 0.7774, 0.1591],\n",
              "        [0.3636, 0.5845, 0.5779],\n",
              "        [0.6733, 0.4907, 0.3294]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QZwTRBb_Xew",
        "outputId": "6fbbaca1-79a7-4f17-84ea-aa946834ddf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "A+B[:, None]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3664, 0.7774, 0.1591],\n",
              "        [1.3636, 1.5845, 1.5779],\n",
              "        [2.6733, 2.4907, 2.3294]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZRz-Tr0HSjb",
        "outputId": "9a8ecf06-c6e1-431c-90ac-69ac3a801816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "A = torch.rand(3,1); A"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2974],\n",
              "        [0.3833],\n",
              "        [0.9836]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNoWaFEpArT"
      },
      "source": [
        "# 6. Dado dos tensores lineales de tamaño n×2 y m×2 respectivamente, crea una matriz de n×m en donde la entrada (i,j) sea la distancia euclideana entre el punto i del primero tensor y el punto j del segundo tensor. Igual, la palabra for está prohibida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fH1BYe0tscx",
        "outputId": "ae428f54-4992-4a56-dde0-829d1236e77c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "def euclidan_distan(n,m):\n",
        "  # Creamos dos tensores de dimensiones nx2 y mx2 con valores aleatorios de entre 0 y 10 \n",
        "  A = torch.randint(0,10,(m,2)); A = A.float()\n",
        "  B = torch.randint(0,10,(n,2)); B = B.float()\n",
        "  \n",
        "  # .cdist nos devuelve la distancia euclidiana entre tensores, tomando como entrada \n",
        "  # dos tensores donde p=2 corresponde a la distancia euclidiana \n",
        "  C = torch.cdist(A, B, p=2, compute_mode='use_mm_for_euclid_dist')\n",
        "  #print(A,\"\\n\\n\", B,\"\\n\",C.shape,C.T.shape)\n",
        "  #print(\"CCC\",C, \"\\n\")\n",
        "  #matrix = A+B[:, None]\n",
        "  #print(C.T)\n",
        "  print(A,\"\\n\\n\", B,\"\\n\")\n",
        "  return(C.T)\n",
        "\n",
        "euclidan_distan(3,3)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 6.],\n",
            "        [8., 5.],\n",
            "        [5., 3.]]) \n",
            "\n",
            " tensor([[3., 0.],\n",
            "        [4., 8.],\n",
            "        [8., 5.]]) \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.3246, 7.0711, 3.6056],\n",
              "        [3.6056, 5.0000, 5.0990],\n",
              "        [7.0711, 0.0000, 3.6056]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KsRVPYA_jJg",
        "outputId": "d3a6a8e6-3a2d-4f73-c430-daf9d2a5f90c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\"\"\"n = 2; m = 3\n",
        "A = torch.randint(0,10,(m,2)); A = A.float()\n",
        "print(\"\\n\",A,\"\\n\")\n",
        "B = torch.randint(0,10,(n,2))\n",
        "B = B.float()\n",
        "print(\"\\n\",B,\"\\n\")\n",
        "C = torch.cdist(A, B, p=2, compute_mode='use_mm_for_euclid_dist')\n",
        "print(\"C\\n\",C, \"\\n\", C.shape)\n",
        "matrix = A+B[:, None]\n",
        "#matrix = matrix.reshape(n,m)\n",
        "print(matrix, matrix.shape)\"\"\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'n = 2; m = 3\\nA = torch.randint(0,10,(m,2)); A = A.float()\\nprint(\"\\n\",A,\"\\n\")\\nB = torch.randint(0,10,(n,2))\\nB = B.float()\\nprint(\"\\n\",B,\"\\n\")\\nC = torch.cdist(A, B, p=2, compute_mode=\\'use_mm_for_euclid_dist\\')\\nprint(\"C\\n\",C, \"\\n\", C.shape)\\nmatrix = A+B[:, None]\\n#matrix = matrix.reshape(n,m)\\nprint(matrix, matrix.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFPOZsrF_izo",
        "outputId": "57a886f4-cb61-486b-f757-b315bc68585e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.arange(2,6)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YGD_DqKzPeT"
      },
      "source": [
        "# 7. Dado una matriz $A$ de $n\\times m$ y un vector de enteros $b$ donde todos los números de $b$ van del 0 a m, selecciona los números en las columnas correspondientes a $b$ y ponlos como $-1$. Por ejemplo, si \n",
        "\n",
        "$$A = \\begin{bmatrix}\n",
        "        0 & 1 & 2 & 3 \\\\\n",
        "        4 & 5 & 6 & 7 \\\\\n",
        "      \\end{bmatrix}$$\n",
        "y $b = [2, 0]$, entonces debe resultar en:\n",
        "\n",
        "$$A = \\begin{bmatrix}\n",
        "        0 & 1 & -1 & 3 \\\\\n",
        "        -1 & 5 & 6 & 7 \\\\\n",
        "      \\end{bmatrix}$$\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjSay4xNzesu",
        "outputId": "37926ab6-b8c1-461b-d6fd-5ed53f7b4c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "def gen_max(n,m):\n",
        "  #print(\"entre\")\n",
        "  #f n>=m:\n",
        "  A = torch.rand(n,m); b = torch.randint(0,m,(n,))\n",
        "  print(A); print(b)\n",
        "  #cuando indezas con arange no te selecciona todo sino que funciona\n",
        "  #como un contador interno. o sea, si pones A[:,:] te regresa toda la matriz A\n",
        "  #pero si pones A[arange, arange] funcionara como \n",
        "  #contador que seleccionara la diagonal\n",
        "  A[torch.arange(b.shape[0]), b] = -1\n",
        "  \n",
        "  return(A)\n",
        "\n",
        "n = 6; m = 6\n",
        "gen_max(n,m)\n",
        "\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6.1979e-01, 7.0634e-01, 1.6900e-01, 5.4990e-01, 9.7142e-01, 4.4149e-03],\n",
            "        [3.1596e-01, 5.5254e-01, 1.9206e-01, 1.8683e-01, 4.1000e-01, 4.2057e-01],\n",
            "        [6.9837e-01, 4.6353e-01, 7.8652e-02, 7.7124e-01, 7.6354e-05, 9.0258e-01],\n",
            "        [5.0004e-01, 5.8152e-01, 3.7842e-01, 5.3923e-01, 3.0643e-01, 9.6395e-01],\n",
            "        [5.1898e-01, 2.4334e-01, 4.9495e-01, 9.9774e-01, 3.0922e-01, 1.9330e-01],\n",
            "        [8.8341e-01, 9.3300e-01, 2.7241e-01, 6.5700e-01, 6.0627e-01, 1.5415e-01]])\n",
            "tensor([1, 0, 1, 0, 1, 0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.1979e-01, -1.0000e+00,  1.6900e-01,  5.4990e-01,  9.7142e-01,\n",
              "          4.4149e-03],\n",
              "        [-1.0000e+00,  5.5254e-01,  1.9206e-01,  1.8683e-01,  4.1000e-01,\n",
              "          4.2057e-01],\n",
              "        [ 6.9837e-01, -1.0000e+00,  7.8652e-02,  7.7124e-01,  7.6354e-05,\n",
              "          9.0258e-01],\n",
              "        [-1.0000e+00,  5.8152e-01,  3.7842e-01,  5.3923e-01,  3.0643e-01,\n",
              "          9.6395e-01],\n",
              "        [ 5.1898e-01, -1.0000e+00,  4.9495e-01,  9.9774e-01,  3.0922e-01,\n",
              "          1.9330e-01],\n",
              "        [-1.0000e+00,  9.3300e-01,  2.7241e-01,  6.5700e-01,  6.0627e-01,\n",
              "          1.5415e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfrR3ZseUFyq",
        "outputId": "dab07fca-229a-4aaf-f9c6-7889e1c906e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m = 5\n",
        "torch.randint(0,m,(m,))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 1, 4, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf2rIieG4ncK",
        "outputId": "1aab55c0-da65-427e-dded-36204b7ea196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# estas son pruebas así que no prestes atencióón a esto, la funcióón gen_max es la que funciona\n",
        "# solo que estaba teniendo problemas con n y m pero leyendo bien el problema lo entendíí \n",
        "# Dado que Carlos nos pidio que dejaramos los experimentos, por eso lo hice\n",
        "\n",
        "#n = 3; m = 5\n",
        "def gen_matrix(n,m):\n",
        "  A = torch.rand(n,m)\n",
        "  #A = torch.randint(0,10,(n,m))\n",
        "  #A[n,torch.arange(b.shape[0])] = -1\n",
        "  b = torch.arange(m)\n",
        "  #print(b.shape)\n",
        "  if n <= m:\n",
        "    A[torch.arange(b.shape[0]), b] = -1\n",
        "    return(A)\n",
        "  elif m <= n:\n",
        "    #A[torch.arange(b.shape[0]), b] = -1\n",
        "    A[b,torch.arange(b.shape[0])] = -1\n",
        "    return(A)\n",
        " #n = 3; m = 5 \n",
        "A = torch.rand(6,3);b = torch.arange(3)\n",
        "gen_matrix(6,3), A, b"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-1.0000,  0.4213,  0.9639],\n",
              "         [ 0.6980, -1.0000,  0.7379],\n",
              "         [ 0.8960,  0.7924, -1.0000],\n",
              "         [ 0.4633,  0.4073,  0.6844],\n",
              "         [ 0.4599,  0.2999,  0.1535],\n",
              "         [ 0.8547,  0.7504,  0.8206]]), tensor([[0.5109, 0.5347, 0.8920],\n",
              "         [0.8237, 0.1743, 0.0202],\n",
              "         [0.8009, 0.0441, 0.4389],\n",
              "         [0.6005, 0.8294, 0.3218],\n",
              "         [0.4031, 0.9875, 0.2767],\n",
              "         [0.2024, 0.7467, 0.0479]]), tensor([0, 1, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFLDAQDf_yOW"
      },
      "source": [
        "#8. (**difícil**) Implementa, sin usar `@` ni matmul, multiplicación de matrices. Se vale usar `*`, `+`, `sum` y broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqFe9BpzG5tf",
        "outputId": "6e77a14e-4d2e-4594-d17e-a9f14e8ed23a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "n= 3; m=4\n",
        "\n",
        "#A(3, 5)\n",
        "#B(5,7)\n",
        "\n",
        "A = torch.randint(1,11,(n,m)); B = torch.randint(1,11,(m,n))\n",
        "#A = A[:,:,None]\n",
        "#B = B[None,:,:]\n",
        "\n",
        "A = A.unsqueeze(1)\n",
        "\n",
        "result = A*B.T\n",
        "\n",
        "#result = (A.T*B.T)\n",
        "#tensor.sum(result)\n",
        "#(3,5,1)\n",
        "#(1,5,7)\n",
        "\n",
        "#ATransformado*BTransformado.sum(dim==??)\n",
        "\n",
        "torch.sum(result, -1), A@B"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[196,  54, 166],\n",
              "         [146,  37, 120],\n",
              "         [198,  87, 156]]), tensor([[[196,  54, 166]],\n",
              " \n",
              "         [[146,  37, 120]],\n",
              " \n",
              "         [[198,  87, 156]]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97PKMZ5p4Ury",
        "outputId": "1b5d930c-4bb8-4406-9685-ea4e09597345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "print(A,\"\\n\\n\",B)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[9, 2, 4, 9]],\n",
            "\n",
            "        [[1, 2, 7, 7]],\n",
            "\n",
            "        [[2, 9, 8, 6]]]) \n",
            "\n",
            " tensor([[ 8,  2,  7],\n",
            "        [ 6,  7,  4],\n",
            "        [10,  1,  8],\n",
            "        [ 8,  2,  7]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIg6erEA_2KA",
        "outputId": "c4b97124-ad90-4651-af17-ab9084df7686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "def notmul(n,m):\n",
        "  A = torch.randint(1,11,(n,m)); B = torch.randint(1,11,(m,n))\n",
        "  A = A.unsqueeze(1); B = B.T\n",
        "  result = A*B\n",
        "  return(torch.sum(result, -1))\n",
        "\n",
        "n = 3; m=4\n",
        "notmul(n,m)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[130,  56, 124],\n",
              "        [148,  66, 152],\n",
              "        [ 80,  37,  86]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvJ3l09CU-yH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}